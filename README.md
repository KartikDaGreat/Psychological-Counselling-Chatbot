Abstract:
The mental state of a person is very difficult to assess without taking multiple factors into account such as his facial emotions, body language as well as intonation. This is more so observed when we attempt to use an interactive way to engage and help patients through chatbots. Researchers have built chatbots that take 2 factors into account, which showed some early signs of results, but was too general for the circumstance, and so this paper presents a 3-modal approach (speech to text, facial emotion recognition and body pose emotion intensity recognition). It uses multiple machine learning algorithms and an 18-point intensity scaling to understand the current state a patient is in and then give a consultation from a hybrid dataset, with a response vetted by psychologists. The responses are shown to give highly intricate answers tailored to the exact requirement of the patient, and shows a promising result.
